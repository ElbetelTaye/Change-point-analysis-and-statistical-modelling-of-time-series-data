{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to brent_oil_prices_yf.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download Brent oil historical data\n",
    "brent = yf.download(\"BZ=F\", start=\"1987-01-01\", end=\"2023-12-31\")\n",
    "brent.to_csv('../data/brent_oil_prices_yf.csv')\n",
    "print(\"Data saved to brent_oil_prices_yf.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To scrape relevant events from a Wikipedia page (e.g., \"Timeline of the oil industry\" or a specific list of global events) for the years 1987-2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events data saved to oil_related_events.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Wikipedia page with oil industry-related events\n",
    "url = 'https://en.wikipedia.org/wiki/Price_of_oil'  # Replace with a relevant page\n",
    "\n",
    "# Send a GET request to fetch page content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the relevant sections for events (you'll need to check the structure of the page)\n",
    "events = []\n",
    "\n",
    "# Example: looking for events in <li> tags under certain headers\n",
    "for li in soup.find_all('li'):\n",
    "    # This may require adjustment based on the structure of the page\n",
    "    text = li.get_text()\n",
    "    year = text[:4]\n",
    "    # Filter only events within the date range\n",
    "    if year.isdigit() and 1987 <= int(year) <= 2023:\n",
    "        events.append({\n",
    "            'Year': int(year),\n",
    "            'Event': text[5:]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "events_df = pd.DataFrame(events)\n",
    "\n",
    "# Save to CSV\n",
    "events_df.to_csv('brent_oil_related_events.csv', index=False)\n",
    "print(\"Events data saved to oil_related_events.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching news data: You are trying to request results too far in the past. Your plan permits you to request articles as far back as 2024-10-01, but you have requested 1987-01-01. You may need to upgrade to a paid plan.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define API endpoint and parameters\n",
    "api_key = '632e57a9a634435aaac5a1770fa256b4'  # Replace with your actual News API key\n",
    "url = 'https://newsapi.org/v2/everything'\n",
    "params = {\n",
    "    'q': 'Brent crude oil',\n",
    "    'from': '1987-01-01',  # Start date\n",
    "    'to': '2023-12-31',    # End date\n",
    "    'sortBy': 'relevancy',\n",
    "    'language': 'en',\n",
    "    'apiKey': api_key\n",
    "}\n",
    "\n",
    "# Fetch data\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Check if data retrieval was successful\n",
    "if data['status'] == 'ok':\n",
    "    articles = data['articles']\n",
    "    # Convert to DataFrame\n",
    "    news_df = pd.DataFrame(articles)\n",
    "    news_df = news_df[['publishedAt', 'title', 'description', 'url']]\n",
    "    news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt'])\n",
    "    news_df.to_csv('brent_crude_news.csv', index=False)\n",
    "    print(\"News data saved to brent_crude_news.csv\")\n",
    "else:\n",
    "    print(\"Error fetching news data:\", data['message'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elbetel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
